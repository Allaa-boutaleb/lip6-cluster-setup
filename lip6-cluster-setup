#!/bin/bash
# =============================================================================
# LIP6 Cluster Setup Script
# Automates SSH, HPC (OAR), and Convergence (SLURM) configuration
#
# Author: Allaa Boutaleb (allaa.boutaleb@lip6.fr)
#
# Usage:
#   ./lip6-cluster-setup            Run the setup wizard
#   ./lip6-cluster-setup --reset    Reset/uninstall (local or full)
# =============================================================================
set -e

BLUE='\033[1;34m'
GREEN='\033[1;32m'
YELLOW='\033[1;33m'
RED='\033[1;31m'
CYAN='\033[1;36m'
DIM='\033[2m'
BOLD='\033[1m'
NC='\033[0m'

SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"

# ---- In-place status helpers ----

status_line() { printf "\r\033[K%s" "$1"; }
status_done() { printf "\r\033[K%s\n" "$1"; }

# ---- Reset mode ----

if [ "$1" = "--reset" ] || [ "$1" = "--uninstall" ]; then
    echo ""
    echo -e "${YELLOW}================================================${NC}"
    echo -e "${YELLOW}  LIP6 Cluster Setup — Reset / Uninstall${NC}"
    echo -e "${YELLOW}================================================${NC}"
    echo ""
    echo -e "${BOLD}What do you want to reset?${NC}"
    echo ""
    echo -e "  ${GREEN}1${NC})  Local only"
    echo -e "      ${DIM}Removes ~/hpc-notebook, ~/conv-manager, SSH config, local aliases${NC}"
    echo ""
    echo -e "  ${GREEN}2${NC})  Full reset (local + remote)"
    echo -e "      ${DIM}Also restores .bashrc on HPC and Convergence from backup${NC}"
    echo ""
    echo -e "  ${CYAN}0${NC})  Cancel"
    echo ""
    read -p "> " reset_choice

    case $reset_choice in
        0) echo -e "\n${DIM}Cancelled.${NC}\n"; exit 0 ;;
        1|2) ;;
        *) echo -e "${RED}Invalid choice.${NC}"; exit 1 ;;
    esac

    # Full reset: restore remote .bashrc FIRST (while SSH config still works)
    if [ "$reset_choice" = "2" ]; then
        echo ""
        echo -e "${CYAN}Resetting remote .bashrc files...${NC}"
        echo -e "${DIM}This requires SSH access (done before removing local SSH config).${NC}"
        echo ""

        hpc_ok=false
        conv_ok=false

        # Try HPC — single SSH call
        status_line "  HPC:          ● Testing..."
        hpc_result=$(ssh -o ConnectTimeout=10 hpc '
            if [ -f ~/.bashrc.pre-lip6-setup ]; then
                cp ~/.bashrc.pre-lip6-setup ~/.bashrc
                echo "RESTORED"
            else
                echo "NO_BACKUP"
            fi
        ' 2>/dev/null) || hpc_result=""

        if [ "$hpc_result" = "RESTORED" ]; then
            status_done "  HPC:          $(echo -e "${GREEN}✓ Restored .bashrc from backup${NC}")"
            hpc_ok=true
        elif [ "$hpc_result" = "NO_BACKUP" ]; then
            status_done "  HPC:          $(echo -e "${YELLOW}No backup found (.bashrc.pre-lip6-setup)${NC}")"
            hpc_ok=true
        else
            status_done "  HPC:          $(echo -e "${DIM}✗ Skipped (not configured or unreachable)${NC}")"
        fi

        # Try Convergence — single SSH call
        status_line "  Convergence:  ● Testing..."
        conv_result=$(ssh -o ConnectTimeout=10 conv '
            if [ -f ~/.bashrc.pre-lip6-setup ]; then
                cp ~/.bashrc.pre-lip6-setup ~/.bashrc
                echo "RESTORED"
            else
                echo "NO_BACKUP"
            fi
        ' 2>/dev/null) || conv_result=""

        if [ "$conv_result" = "RESTORED" ]; then
            status_done "  Convergence:  $(echo -e "${GREEN}✓ Restored .bashrc from backup${NC}")"
            conv_ok=true
        elif [ "$conv_result" = "NO_BACKUP" ]; then
            status_done "  Convergence:  $(echo -e "${YELLOW}No backup found (.bashrc.pre-lip6-setup)${NC}")"
            conv_ok=true
        else
            status_done "  Convergence:  $(echo -e "${DIM}✗ Skipped (not configured or unreachable)${NC}")"
        fi

        # If both unreachable, warn before destroying local config
        if ! $hpc_ok && ! $conv_ok; then
            echo ""
            echo -e "${YELLOW}Both remote servers are unreachable.${NC}"
            echo -e "${YELLOW}Continuing will destroy local SSH config without restoring remote .bashrc files.${NC}"
            echo ""
            read -p "Continue anyway? (y/N) " confirm
            if [ "$confirm" != "y" ] && [ "$confirm" != "Y" ]; then
                echo -e "\n${DIM}Cancelled.${NC}\n"
                exit 0
            fi
        fi
    fi

    echo ""
    echo -e "${CYAN}Resetting local setup...${NC}"
    echo ""

    # Remove local scripts
    for f in ~/hpc-notebook ~/conv-manager; do
        if [ -f "$f" ]; then
            rm "$f"
            echo -e "  ${GREEN}✓ Removed${NC} $f"
        else
            echo -e "  ${DIM}Already gone:${NC} $f"
        fi
    done

    # Remove LIP6 SSH config
    if [ -f ~/.ssh/config.d/lip6 ]; then
        rm ~/.ssh/config.d/lip6
        echo -e "  ${GREEN}✓ Removed${NC} ~/.ssh/config.d/lip6"
    fi
    # Restore main SSH config from backup (in case Include was added)
    LATEST_BACKUP=$(ls -t ~/.ssh/config.backup.* 2>/dev/null | head -1)
    if [ -n "$LATEST_BACKUP" ]; then
        cp "$LATEST_BACKUP" ~/.ssh/config
        echo -e "  ${GREEN}✓ Restored${NC} SSH config from backup (${LATEST_BACKUP})"
    else
        echo -e "  ${DIM}No SSH config backup to restore.${NC}"
    fi

    # Remove aliases from shell configs
    for rc in ~/.bashrc ~/.zshrc ~/.config/fish/config.fish; do
        if [ -f "$rc" ] && grep -q 'alias hpc=\|alias conv=' "$rc" 2>/dev/null; then
            tmpfile=$(mktemp "${rc}.XXXXXX")
            grep -v 'alias hpc=' "$rc" | grep -v 'alias conv=' > "$tmpfile" 2>/dev/null || true
            mv "$tmpfile" "$rc"
            echo -e "  ${GREEN}✓ Cleaned${NC} aliases from $rc"
        fi
    done

    echo ""
    echo -e "${GREEN}Reset complete.${NC} Run the script again to reconfigure."
    echo ""
    exit 0
fi

# ---- Helper: validated input ----

# ask PROMPT DEFAULT REGEX ERROR_MSG
# Loops until input matches REGEX. Prints result to stdout.
# Prompts and errors go to stderr so they don't mix with the return value.
ask() {
    local prompt="$1"
    local default="$2"
    local regex="$3"
    local error_msg="${4:-Invalid input. Try again.}"
    local result=""

    while true; do
        if [ -n "$default" ]; then
            echo -ne "${BOLD}${prompt}${NC} [${DIM}${default}${NC}]: " >&2
            read result
            result="${result:-$default}"
        else
            echo -ne "${BOLD}${prompt}${NC}: " >&2
            read result
        fi

        if [ -z "$result" ]; then
            echo -e "  ${RED}This field is required.${NC}" >&2
            continue
        fi

        if [ -z "$regex" ] || echo "$result" | grep -qE "$regex"; then
            echo "$result"
            return 0
        fi
        echo -e "  ${RED}${error_msg}${NC}" >&2
    done
}

# ask_choice PROMPT MAX_OPTIONS [DEFAULT]
# Loops until user enters a number between 1 and MAX_OPTIONS.
ask_choice() {
    local prompt="$1"
    local max="$2"
    local default="${3:-}"
    local result=""

    while true; do
        if [ -n "$default" ]; then
            echo -ne "${DIM}${prompt} [${default}]:${NC} " >&2
            read result
            result="${result:-$default}"
        else
            echo -ne "${DIM}${prompt}:${NC} " >&2
            read result
        fi

        if echo "$result" | grep -qE "^[1-${max}]$"; then
            echo "$result"
            return 0
        fi
        echo -e "  ${RED}Please enter a number between 1 and ${max}.${NC}" >&2
    done
}

# ---- Welcome ----

echo ""
echo -e "${BLUE}================================================================${NC}"
echo -e "${BOLD}            LIP6 Cluster Setup${NC}"
echo -e "${DIM}   Automated configuration for HPC (OAR) & Convergence (SLURM)${NC}"
echo -e "${DIM}   By Allaa Boutaleb (allaa.boutaleb@lip6.fr)${NC}"
echo -e "${BLUE}================================================================${NC}"
echo ""
echo -e "${DIM}This script will:${NC}"
echo -e "  1. Generate an SSH key (if needed)"
echo -e "  2. Configure passwordless SSH access"
echo -e "  3. Install cluster manager tools (hpc, conv)"
echo -e "  4. Set up aliases on remote clusters"
echo ""
echo -e "${YELLOW}You will need:${NC}"
echo -e "  - Your LIP6 username"
echo -e "  - Your LIP6 secure password (wifi/workstation, NOT email)"
echo -e "  - To know which clusters you have access to"
echo ""
read -p "Press Enter to continue..."

# ---- Gather info ----

echo ""
echo -e "${BOLD}Step 1: Your information${NC}"
echo ""

USERNAME=$(ask \
    "LIP6 username (lowercase letters, digits, underscores — e.g. boutalebm)" \
    "" \
    "^[a-z][a-z0-9_]+$" \
    "Username must start with a letter and contain only lowercase letters, digits, or underscores.")

EMAIL=$(ask \
    "Email (e.g. firstname.lastname@lip6.fr)" \
    "" \
    "^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$" \
    "Must be a valid email address (letters, digits, dots — e.g. firstname.lastname@lip6.fr).")

echo ""
echo -e "${BOLD}Which team are you on?${NC}"
echo ""
echo -e "  ${GREEN}1${NC})  ALMASTY, APR, BD, ComplexNetworks, DECISION, DELYS,"
echo -e "      LFI, MOCAH, MoVe, NPA, PEQUAN, PolSys, RO, SMA"
echo -e "      ${DIM}(Gateway: ssh.lip6.fr)${NC}"
echo ""
echo -e "  ${GREEN}2${NC})  ALSOC, CIAN, QI, SYEL"
echo -e "      ${DIM}(Gateway: barder.lip6.fr)${NC}"
echo ""
team_choice=$(ask_choice "Select your team group (1 or 2)" 2 1)

case $team_choice in
    2) GATEWAY="barder.lip6.fr" ;;
    *) GATEWAY="ssh.lip6.fr" ;;
esac

# Determine NFS storage path based on team
echo ""
echo -e "${BOLD}Which group does your team belong to?${NC}"
echo -e "${DIM}This determines your NFS storage path on the HPC cluster.${NC}"
echo ""
echo -e "  ${GREEN}1${NC})  ACASA, BD, DECISION, DELYS, LFI, MLIA, MOCAH, MoVe, RO, SMA"
echo -e "      ${DIM}(Storage: /net/big/\${USER})${NC}"
echo ""
echo -e "  ${GREEN}2${NC})  ALMASTY, APR, ComplexNetworks, NPA, PEQUAN, Phare, PolSys"
echo -e "      ${DIM}(Storage: /home/cluster/\${USER})${NC}"
echo ""
echo -e "  ${GREEN}3${NC})  Not sure / other"
echo ""
storage_choice=$(ask_choice "Select your storage group (1, 2, or 3)" 3 1)

case $storage_choice in
    1) HPC_STORAGE="/net/big/${USERNAME}" ;;
    2) HPC_STORAGE="/home/cluster/${USERNAME}" ;;
    *) HPC_STORAGE="~/  (check with your team)" ;;
esac

echo ""
echo -e "${BOLD}Which clusters do you need access to?${NC}"
echo ""
echo -e "  ${GREEN}1${NC})  HPC only (CPU cluster, OAR scheduler)"
echo -e "  ${GREEN}2${NC})  Convergence only (GPU cluster, A100s, SLURM scheduler)"
echo -e "  ${GREEN}3${NC})  Both (recommended)"
echo ""
cluster_choice=$(ask_choice "Select clusters to configure (1, 2, or 3)" 3 3)

SETUP_HPC=false
SETUP_CONV=false
case $cluster_choice in
    1) SETUP_HPC=true ;;
    2) SETUP_CONV=true ;;
    *) SETUP_HPC=true; SETUP_CONV=true ;;
esac

# ---- Confirm ----

echo ""
echo -e "${BLUE}────────────────────────────────────────────────${NC}"
echo -e "${BOLD}  Please confirm:${NC}"
echo ""
echo -e "  Username:     ${CYAN}${USERNAME}${NC}"
echo -e "  Email:        ${CYAN}${EMAIL}${NC}"
echo -e "  Gateway:      ${CYAN}${GATEWAY}${NC}"
echo -e "  Storage:      ${CYAN}${HPC_STORAGE}${NC}"
echo -e "  HPC (OAR):    ${CYAN}$($SETUP_HPC && echo "Yes" || echo "No")${NC}"
echo -e "  Convergence:  ${CYAN}$($SETUP_CONV && echo "Yes" || echo "No")${NC}"
echo ""
echo -e "${BLUE}────────────────────────────────────────────────${NC}"
echo ""
echo -e "${DIM}Press Enter to continue, or Ctrl+C to abort.${NC}"
read

# ---- SSH Key ----

echo ""
echo -e "${BOLD}Step 2: SSH key${NC}"
echo ""

SSH_KEY="$HOME/.ssh/id_ed25519"
if [ -f "$SSH_KEY" ]; then
    status_done "  $(echo -e "${GREEN}✓${NC} SSH key exists: $SSH_KEY")"
else
    status_line "  ● Generating SSH key..."
    mkdir -p ~/.ssh
    ssh-keygen -t ed25519 -C "$EMAIL" -f "$SSH_KEY" -N ""
    status_done "  $(echo -e "${GREEN}✓${NC} SSH key generated: $SSH_KEY")"
    echo ""
    echo -e "${YELLOW}Note:${NC} The key was created without a passphrase for convenience."
    echo -e "${DIM}To add a passphrase later: ssh-keygen -p -f $SSH_KEY${NC}"
fi

chmod 700 ~/.ssh
chmod 600 "$SSH_KEY"
chmod 644 "${SSH_KEY}.pub"

# ---- SSH Config ----

echo ""
echo -e "${BOLD}Step 3: SSH config${NC}"
echo ""

SSH_CONFIG="$HOME/.ssh/config"
SSH_LIP6_CONFIG="$HOME/.ssh/config.d/lip6"

# Backup existing config
if [ -f "$SSH_CONFIG" ]; then
    cp "$SSH_CONFIG" "${SSH_CONFIG}.backup.$(date +%s)"
fi

# Use Include-based approach to preserve existing SSH config entries
mkdir -p "$HOME/.ssh/config.d"
if [ ! -f "$SSH_CONFIG" ] || ! grep -q 'Include config.d/\*' "$SSH_CONFIG" 2>/dev/null; then
    # Prepend Include directive (must be at top of config)
    if [ -f "$SSH_CONFIG" ]; then
        tmpfile=$(mktemp "${SSH_CONFIG}.XXXXXX")
        echo "Include config.d/*" > "$tmpfile"
        echo "" >> "$tmpfile"
        cat "$SSH_CONFIG" >> "$tmpfile"
        mv "$tmpfile" "$SSH_CONFIG"
    else
        echo "Include config.d/*" > "$SSH_CONFIG"
    fi
fi

# Build LIP6-specific config in config.d/
{
    echo "# ==================================================================="
    echo "# LIP6 Cluster SSH Config"
    echo "# Generated by lip6-cluster-setup on $(date +%Y-%m-%d)"
    echo "# ==================================================================="
    echo ""
    echo "Host lip6"
    echo "    HostName $GATEWAY"
    echo "    User $USERNAME"
    echo "    IdentityFile $SSH_KEY"
    echo "    IdentitiesOnly yes"
    echo "    StrictHostKeyChecking accept-new"
    echo ""

    if $SETUP_HPC; then
        echo "Host hpc"
        echo "    HostName cluster.lip6.fr"
        echo "    User $USERNAME"
        echo "    ProxyJump lip6"
        echo "    IdentityFile $SSH_KEY"
        echo "    IdentitiesOnly yes"
        echo "    ServerAliveInterval 60"
        echo "    ServerAliveCountMax 3"
        echo "    StrictHostKeyChecking accept-new"
        echo ""
    fi

    if $SETUP_CONV; then
        echo "Host conv"
        echo "    HostName front.convergence.lip6.fr"
        echo "    User $USERNAME"
        echo "    ProxyJump lip6"
        echo "    IdentityFile $SSH_KEY"
        echo "    IdentitiesOnly yes"
        echo "    ServerAliveInterval 60"
        echo "    ServerAliveCountMax 3"
        echo "    StrictHostKeyChecking accept-new"
        echo ""
        echo "Host *.convergence.lip6.fr"
        echo "    User $USERNAME"
        echo "    ProxyJump conv"
        echo "    IdentityFile $SSH_KEY"
        echo "    IdentitiesOnly yes"
        echo "    ServerAliveInterval 60"
        echo "    ServerAliveCountMax 3"
        echo "    StrictHostKeyChecking accept-new"
        echo ""
    fi
} > "$SSH_LIP6_CONFIG"

chmod 600 "$SSH_CONFIG"
chmod 600 "$SSH_LIP6_CONFIG"
status_done "  $(echo -e "${GREEN}✓${NC} SSH config written to ${SSH_LIP6_CONFIG}")"

# ---- Copy SSH Keys ----

echo ""
echo -e "${BOLD}Step 4: Copying SSH key to servers${NC}"
echo ""
echo -e "${YELLOW}You will be asked for your LIP6 password a few times.${NC}"
echo -e "${DIM}This is the LAST time you'll ever need to type it.${NC}"
echo ""
read -p "Press Enter to continue..."

echo ""
echo -e "${CYAN}Copying key to gateway (${GATEWAY})...${NC}"
ssh-copy-id -i "${SSH_KEY}.pub" "${USERNAME}@${GATEWAY}" || {
    echo -e "${RED}Failed to copy key to gateway. Check your password.${NC}"
    exit 1
}

if $SETUP_HPC; then
    echo ""
    echo -e "${CYAN}Copying key to HPC cluster...${NC}"
    ssh-copy-id -o "ProxyJump=${USERNAME}@${GATEWAY}" -i "${SSH_KEY}.pub" "${USERNAME}@cluster.lip6.fr" || {
        echo -e "${RED}Failed to copy key to HPC. You may not have HPC access.${NC}"
    }
fi

if $SETUP_CONV; then
    echo ""
    echo -e "${CYAN}Copying key to Convergence...${NC}"
    ssh-copy-id -o "ProxyJump=${USERNAME}@${GATEWAY}" -i "${SSH_KEY}.pub" "${USERNAME}@front.convergence.lip6.fr" || {
        echo -e "${RED}Failed to copy key to Convergence. You may not have access.${NC}"
    }

    echo ""
    echo -e "${CYAN}Setting up node-to-node SSH on Convergence...${NC}"
    ssh conv "
        if [ ! -f ~/.ssh/id_ed25519 ]; then
            ssh-keygen -t ed25519 -N '' -f ~/.ssh/id_ed25519 -q
        fi
        grep -qF \"\$(cat ~/.ssh/id_ed25519.pub)\" ~/.ssh/authorized_keys 2>/dev/null || cat ~/.ssh/id_ed25519.pub >> ~/.ssh/authorized_keys
        chmod 600 ~/.ssh/authorized_keys
    " 2>/dev/null && echo -e "${GREEN}Node-to-node SSH configured.${NC}" || echo -e "${YELLOW}Could not auto-configure node SSH. You can do this manually later.${NC}"
fi

# ---- Test connections ----

echo ""
echo -e "${BOLD}Step 5: Testing connections${NC}"
echo ""

if $SETUP_HPC; then
    status_line "  HPC:          ● Testing..."
    if ssh -o ConnectTimeout=10 hpc "echo ok" 2>/dev/null | grep -q ok; then
        status_done "  HPC:          $(echo -e "${GREEN}✓ Connected${NC}")"
    else
        status_done "  HPC:          $(echo -e "${RED}✗ Failed${NC}")"
    fi
fi

if $SETUP_CONV; then
    status_line "  Convergence:  ● Testing..."
    if ssh -o ConnectTimeout=10 conv "echo ok" 2>/dev/null | grep -q ok; then
        status_done "  Convergence:  $(echo -e "${GREEN}✓ Connected${NC}")"
    else
        status_done "  Convergence:  $(echo -e "${RED}✗ Failed${NC}")"
    fi
fi

# ---- Install manager scripts ----

echo ""
echo -e "${BOLD}Step 6: Installing cluster manager tools${NC}"
echo ""

INSTALL_DIR="$HOME"

if $SETUP_HPC; then
    # Generate HPC manager
    cat > "${INSTALL_DIR}/hpc-notebook" << 'HPC_SCRIPT'
#!/bin/bash
# HPC Manager for LIP6 Cluster
# __USERNAME__ - __EMAIL__

BLUE='\033[1;34m'
GREEN='\033[1;32m'
YELLOW='\033[1;33m'
RED='\033[1;31m'
CYAN='\033[1;36m'
DIM='\033[2m'
BOLD='\033[1m'
NC='\033[0m'

HPC_USER="__USERNAME__"

is_int()  { [[ "$1" =~ ^[0-9]+$ ]]; }
is_name() { [[ "$1" =~ ^[a-zA-Z0-9_.-]+$ ]]; }
is_path() { [[ "$1" =~ ^[a-zA-Z0-9_.~/-]+$ ]]; }

status_line() { printf "\r\033[K%s" "$1"; }
status_done() { printf "\r\033[K%s\n" "$1"; }
spin_chars=('⠋' '⠙' '⠹' '⠸' '⠼' '⠴' '⠦' '⠧' '⠇' '⠏')

# parse_duration INPUT
# Accepts: 30m, 8h, 3d, 3d 12h, 1d 6h 30m, H:M:S, bare number (hours)
# Outputs OAR-compatible H:M:S to stdout. Returns 1 on invalid input.
parse_duration() {
    local input="${*,,}"  # lowercase
    input=$(echo "$input" | xargs)  # trim
    [ -z "$input" ] && return 1

    # Legacy H:M:S format
    if [[ "$input" =~ ^[0-9]+:[0-9]+:[0-9]+$ ]]; then
        echo "$input"
        return 0
    fi

    local total_minutes=0
    local matched=false

    if [[ "$input" =~ [dhm] ]]; then
        if [[ "$input" =~ ([0-9]+)d ]]; then
            total_minutes=$(( total_minutes + ${BASH_REMATCH[1]} * 1440 ))
            matched=true
        fi
        if [[ "$input" =~ ([0-9]+)h ]]; then
            total_minutes=$(( total_minutes + ${BASH_REMATCH[1]} * 60 ))
            matched=true
        fi
        if [[ "$input" =~ ([0-9]+)m ]]; then
            total_minutes=$(( total_minutes + ${BASH_REMATCH[1]} ))
            matched=true
        fi
        if ! $matched; then return 1; fi
    elif [[ "$input" =~ ^[0-9]+$ ]]; then
        # Bare number = hours
        total_minutes=$(( input * 60 ))
    else
        return 1
    fi

    local hours=$(( total_minutes / 60 ))
    local mins=$(( total_minutes % 60 ))
    echo "${hours}:${mins}:0"
    return 0
}

# Convert total minutes to human-readable string
duration_human() {
    local total_minutes="$1"
    [ -z "$total_minutes" ] || [ "$total_minutes" -le 0 ] 2>/dev/null && { echo "N/A"; return; }
    local d=$(( total_minutes / 1440 ))
    local h=$(( (total_minutes % 1440) / 60 ))
    local m=$(( total_minutes % 60 ))
    local result=""
    [ $d -gt 0 ] && result="${d}d "
    [ $h -gt 0 ] && result="${result}${h}h "
    [ $m -gt 0 ] && result="${result}${m}m"
    echo "${result:-0m}" | xargs
}

welcome() {
    echo ""
    echo -e "${BLUE}================================================${NC}"
    echo -e "${BOLD}         LIP6 HPC Cluster Manager${NC}"
    echo -e "${DIM}    __USERNAME__ - __EMAIL__${NC}"
    echo -e "${BLUE}================================================${NC}"
}

show_menu() {
    echo ""
    echo -e "${BOLD}What do you want to do?${NC}"
    echo ""
    echo -e "  ${GREEN}1${NC})  Launch a new session"
    echo -e "  ${GREEN}2${NC})  Reconnect to a running session"
    echo -e "  ${GREEN}3${NC})  View my jobs"
    echo -e "  ${GREEN}4${NC})  Cancel jobs"
    echo -e "  ${GREEN}5${NC})  SSH into login node"
    echo -e "  ${CYAN}0${NC})  Exit"
    echo ""
}

launch_session() {
    echo ""
    echo -e "${BOLD}How many cores?${NC}"
    echo -e "  ${DIM}Press Enter for 24, or 0 to go back${NC}"
    read -p "> " cores
    [ "$cores" = "0" ] && return
    cores="${cores:-24}"
    if ! is_int "$cores"; then
        echo -e "${RED}Core count must be a number (e.g. 4, 12, 24).${NC}"
        return
    fi

    echo ""
    echo -e "${BOLD}How long do you need?${NC}"
    echo -e "  ${DIM}e.g. 8h, 3d, 1d 6h 30m, 24:0:0 — Enter for 24h, 0 to go back${NC}"
    read -p "> " wall_input
    [ "$wall_input" = "0" ] && return
    wall_input="${wall_input:-24h}"
    wall=$(parse_duration "$wall_input")
    if [ $? -ne 0 ] || [ -z "$wall" ]; then
        echo -e "${RED}Invalid duration. Examples: 8h, 3d, 1d 6h 30m, 8:0:0${NC}"
        return
    fi

    # Duration warning
    local wall_h=${wall%%:*}
    if [ "$wall_h" -gt 24 ] 2>/dev/null; then
        echo -e "${YELLOW}Note: Interactive sessions are typically limited to ~24h. Batch jobs can go up to 1000h.${NC}"
    fi

    echo ""
    echo -e "${BOLD}How do you want to work?${NC}"
    echo ""
    echo -e "  ${GREEN}1${NC})  Jupyter Lab + Terminal  ${DIM}(recommended)${NC}"
    echo -e "      ${DIM}Persistent — survives disconnect. Opens browser + shows SSH command.${NC}"
    echo -e "  ${GREEN}2${NC})  Terminal only  ${DIM}(interactive)${NC}"
    echo -e "      ${DIM}Direct shell on compute node. Ends when you disconnect.${NC}"
    echo -e "  ${GREEN}3${NC})  Submit a custom script"
    echo -e "      ${DIM}Run your own batch script with OAR.${NC}"
    echo -e "  ${CYAN}0${NC})  Back"
    echo ""
    read -p "> " mode
    [ "$mode" = "0" ] && return
    mode="${mode:-1}"
    if ! [[ "$mode" =~ ^[1-3]$ ]]; then
        echo -e "${RED}Choose 1, 2, or 3.${NC}"
        return
    fi

    local port=8888

    if [ "$mode" = "2" ]; then
        echo ""
        echo -e "${CYAN}Requesting interactive session: ${cores} cores, ${wall}...${NC}"
        echo -e "${DIM}This is interactive — ends when you disconnect.${NC}"
        echo ""
        ssh -t hpc "oarsub -l /nodes=1/core=${cores},walltime=${wall} -p \"host like 'big%'\" -I"
        return
    fi

    if [ "$mode" = "3" ]; then
        submit_custom_hpc "$cores" "$wall"
        return
    fi

    echo ""
    echo -e "${CYAN}Submitting job: ${cores} cores, ${wall}...${NC}"

    # Check if Jupyter is available
    status_line "  ● Checking Jupyter installation..."
    jupyter_check=$(ssh hpc 'source /etc/profile.d/modules.sh 2>/dev/null; module purge; module load python/anaconda3; eval "$(conda shell.bash hook)"; which jupyter 2>/dev/null' 2>/dev/null)
    if [ -z "$jupyter_check" ]; then
        status_done "  $(echo -e "${YELLOW}! Jupyter not found. Installing...${NC}")"
        ssh hpc 'source /etc/profile.d/modules.sh 2>/dev/null; module purge; module load python/anaconda3; eval "$(conda shell.bash hook)"; pip install --quiet jupyterlab' 2>/dev/null
        if [ $? -eq 0 ]; then
            echo -e "  ${GREEN}✓ Jupyter Lab installed${NC}"
        else
            echo -e "  ${RED}✗ Failed to install Jupyter. Check manually.${NC}"
            return
        fi
    else
        status_done "  $(echo -e "${GREEN}✓${NC} Jupyter available")"
    fi

    JOBID=$(ssh hpc bash -s "$cores" "$wall" "$port" << 'REMOTE'
CORES="$1"
WALL="$2"
PORT="$3"
cat > ~/._jupyter_job.sh << JOBSCRIPT
#!/bin/bash
#OAR -l {host like 'big%'}/nodes=1/core=${CORES},walltime=${WALL}
#OAR --notify mail:__EMAIL__

source /etc/profile.d/modules.sh
module purge
module load python/anaconda3
eval "\$(conda shell.bash hook)"

jupyter lab --ip=0.0.0.0 --no-browser --port=${PORT}
JOBSCRIPT
chmod +x ~/._jupyter_job.sh
oarsub -S ~/._jupyter_job.sh 2>&1 | grep -oP 'OAR_JOB_ID=\K[0-9]+'
REMOTE
    )

    if [ -z "$JOBID" ] || ! is_int "$JOBID"; then
        echo -e "${RED}Failed to submit job.${NC}"
        return
    fi

    echo -e "${GREEN}Job $JOBID submitted.${NC} Waiting for it to start..."
    sleep 5

    # Trap Ctrl+C during wait
    local wait_interrupted=false
    trap 'wait_interrupted=true' INT

    local attempts=0
    local spin_idx=0
    while true; do
        if $wait_interrupted; then
            status_done ""
            echo ""
            echo -e "${YELLOW}Job $JOBID is still queued. You'll get an email when it starts.${NC}"
            echo -e "Use option 2 to reconnect later."
            trap - INT
            return
        fi
        STATE=$(ssh hpc "oarstat -f -j '$JOBID' 2>/dev/null | grep 'state =' | head -1 | awk -F= '{print \$2}' | tr -d ' '")
        if [ "$STATE" = "Running" ]; then
            status_done "  $(echo -e "${GREEN}✓ Job $JOBID is running${NC}")"
            break
        elif [ "$STATE" = "Error" ] || [ "$STATE" = "Terminated" ]; then
            status_done ""
            echo -e "${RED}Job failed (state: $STATE)${NC}"
            echo -e "Check logs: ${DIM}ssh hpc 'cat ~/OAR.${JOBID}.stderr'${NC}"
            trap - INT
            return
        fi
        attempts=$((attempts + 1))
        if [ $attempts -gt 60 ]; then
            status_done ""
            echo ""
            echo -e "${YELLOW}Job $JOBID is still queued after 5 min. You'll get an email when it starts.${NC}"
            echo -e "Use option 2 to reconnect later."
            trap - INT
            return
        fi
        local sc="${spin_chars[$((spin_idx % ${#spin_chars[@]}))]}"
        spin_idx=$((spin_idx + 1))
        status_line "  ${sc} ${STATE:-PENDING} — waiting for resources ($((attempts * 5))s) — Ctrl+C to stop waiting"
        sleep 5
    done

    trap - INT
    connect_to_job "$JOBID" "$port"
}

submit_custom_hpc() {
    local cores="$1"
    local wall="$2"

    echo ""
    echo -e "${BOLD}Path to your script on the cluster?${NC}"
    echo -e "  ${DIM}e.g. ~/train.sh — 0 to go back${NC}"
    read -p "> " script_path
    [ "$script_path" = "0" ] && return

    if [ -z "$script_path" ]; then
        echo -e "${RED}No script provided.${NC}"
        return
    fi
    if ! is_path "$script_path"; then
        echo -e "${RED}Invalid path. Allowed characters: letters, digits, ., _, ~, /, -${NC}"
        return
    fi

    # Warn if > 1000h
    local wall_h=${wall%%:*}
    if [ "$wall_h" -gt 1000 ] 2>/dev/null; then
        echo -e "${YELLOW}Warning: ${wall_h}h exceeds the typical 1000h batch limit.${NC}"
    fi

    echo ""
    echo -e "${CYAN}Submitting ${script_path}: ${cores} cores, ${wall}...${NC}"

    JOBID=$(ssh hpc "oarsub -l /nodes=1/core=${cores},walltime=${wall} -p \"host like 'big%'\" -S '${script_path}' 2>&1 | grep -oP 'OAR_JOB_ID=\K[0-9]+'")

    if [ -z "$JOBID" ] || ! is_int "$JOBID"; then
        echo -e "${RED}Failed to submit job.${NC}"
        return
    fi

    echo -e "${GREEN}Job $JOBID submitted!${NC}"
    echo -e "  Check status:  ${DIM}option 3${NC}"
    echo -e "  Check logs:    ${DIM}ssh hpc 'cat ~/OAR.${JOBID}.stderr'${NC}"
    echo -e "  Cancel:        ${DIM}option 4${NC}"
}

connect_to_job() {
    local jobid="$1"
    local port="${2:-8888}"

    local node
    node=$(ssh hpc "oarstat -f -j '$jobid' 2>/dev/null | grep 'assigned_hostnames' | awk '{print \$3}'")
    if [ -z "$node" ] || ! is_name "$node"; then
        echo -e "${RED}Could not find node for job $jobid${NC}"
        return
    fi

    echo -e "${CYAN}Running on ${BOLD}$node${NC}${CYAN}. Waiting for Jupyter...${NC}"

    local url=""
    local spin_idx=0
    for i in $(seq 1 30); do
        url=$(ssh hpc "grep -o 'http://[^ ]*' ~/OAR.'${jobid}'.stderr 2>/dev/null | tail -1")
        if [ -n "$url" ]; then
            status_done "  $(echo -e "${GREEN}✓${NC} Jupyter is ready")"
            break
        fi
        local sc="${spin_chars[$((spin_idx % ${#spin_chars[@]}))]}"
        spin_idx=$((spin_idx + 1))
        status_line "  ${sc} Waiting for Jupyter to start... ($((i * 2))s)"
        sleep 2
    done

    if [ -z "$url" ]; then
        status_done ""
        echo -e "${RED}Jupyter didn't start.${NC}"
        echo -e "Check logs: ${DIM}ssh hpc 'cat ~/OAR.${jobid}.stderr'${NC}"
        return
    fi

    local actual_port
    actual_port=$(echo "$url" | grep -oP ':\K[0-9]+(?=/)' | head -1)
    actual_port="${actual_port:-$port}"
    local local_url
    local_url=$(echo "$url" | sed "s|http://[^:]*:|http://localhost:|")

    echo ""
    echo -e "${GREEN}================================================${NC}"
    echo -e "${GREEN}  Session ready!${NC}"
    echo -e "${GREEN}================================================${NC}"
    echo ""
    echo -e "  ${BOLD}Job:${NC}   $jobid"
    echo -e "  ${BOLD}Node:${NC}  $node"
    echo -e "  ${BOLD}URL:${NC}   ${CYAN}$local_url${NC}"
    echo ""
    echo -e "${CYAN}Opening Jupyter in browser...${NC}"
    if command -v xdg-open &>/dev/null; then
        xdg-open "$local_url" 2>/dev/null &
    elif command -v open &>/dev/null; then
        open "$local_url" &
    fi
    echo ""
    echo -e "${BOLD}To open a terminal on $node, run in another tab:${NC}"
    echo ""
    echo -e "  ${GREEN}ssh -t hpc \"OAR_JOB_ID=$jobid oarsh $node\"${NC}"
    echo ""
    echo -e "${DIM}Tunnel active. Ctrl+C to disconnect (job keeps running).${NC}"
    echo ""
    ssh -N -L "${actual_port}:${node}:${actual_port}" hpc
}

my_jobs() {
    echo ""
    status_line "  ● Fetching jobs..."
    local raw
    raw=$(ssh hpc "oarstat -u ${HPC_USER} -f 2>/dev/null" 2>/dev/null)
    if [ -z "$raw" ] || ! echo "$raw" | grep -q "Job_Id"; then
        status_done "  $(echo -e "${DIM}No jobs found.${NC}")"
        echo ""
        return
    fi

    status_done ""

    # Parse oarstat -f output
    local current_id="" current_name="" current_state="" current_wall="" current_start="" current_node=""
    local running_lines=()
    local pending_lines=()

    while IFS= read -r line; do
        if [[ "$line" =~ Job_Id[[:space:]]*:[[:space:]]*([0-9]+) ]]; then
            # Save previous job
            if [ -n "$current_id" ]; then
                if [ "$current_state" = "Running" ]; then
                    running_lines+=("${current_id}|${current_name}|${current_node}|${current_wall}|${current_start}")
                elif [ -n "$current_state" ]; then
                    pending_lines+=("${current_id}|${current_name}|${current_wall}")
                fi
            fi
            current_id="${BASH_REMATCH[1]}"
            current_name="" current_state="" current_wall="" current_start="" current_node=""
        fi
        [[ "$line" =~ name[[:space:]]*=[[:space:]]*(.*) ]] && current_name="${BASH_REMATCH[1]}" && current_name=$(echo "$current_name" | xargs)
        [[ "$line" =~ state[[:space:]]*=[[:space:]]*(.*) ]] && current_state="${BASH_REMATCH[1]}" && current_state=$(echo "$current_state" | xargs)
        [[ "$line" =~ walltime[[:space:]]*=[[:space:]]*(.*) ]] && current_wall="${BASH_REMATCH[1]}" && current_wall=$(echo "$current_wall" | xargs)
        [[ "$line" =~ startTime[[:space:]]*=[[:space:]]*(.*) ]] && current_start="${BASH_REMATCH[1]}" && current_start=$(echo "$current_start" | xargs)
        [[ "$line" =~ assigned_hostnames[[:space:]]*=[[:space:]]*(.*) ]] && current_node="${BASH_REMATCH[1]}" && current_node=$(echo "$current_node" | xargs)
    done <<< "$raw"

    # Don't forget the last job
    if [ -n "$current_id" ]; then
        if [ "$current_state" = "Running" ]; then
            running_lines+=("${current_id}|${current_name}|${current_node}|${current_wall}|${current_start}")
        elif [ -n "$current_state" ]; then
            pending_lines+=("${current_id}|${current_name}|${current_wall}")
        fi
    fi

    if [ ${#running_lines[@]} -gt 0 ]; then
        echo -e "${GREEN}${BOLD}RUNNING${NC}"
        printf "  %-10s %-15s %-10s %-12s %-12s\n" "ID" "Name" "Node" "Elapsed" "Remaining"
        echo -e "  ${DIM}──────────────────────────────────────────────────────────────${NC}"
        for entry in "${running_lines[@]}"; do
            IFS='|' read -r jid jname jnode jwall jstart <<< "$entry"
            # Compute elapsed and remaining
            local start_ts elapsed_str remain_str
            if [[ "$jstart" =~ ^[0-9]+$ ]]; then
                start_ts="$jstart"
            else
                start_ts=$(date -d "$jstart" +%s 2>/dev/null)
            fi
            if [ -n "$start_ts" ] && [ "$start_ts" -gt 0 ] 2>/dev/null; then
                local now_ts=$(date +%s)
                local elapsed_min=$(( (now_ts - start_ts) / 60 ))
                # Parse walltime H:M:S to minutes
                local wh wm ws
                IFS=':' read -r wh wm ws <<< "$jwall"
                local wall_min=$(( wh * 60 + wm ))
                local remain_min=$(( wall_min - elapsed_min ))
                [ $remain_min -lt 0 ] && remain_min=0
                elapsed_str=$(duration_human $elapsed_min)
                remain_str=$(duration_human $remain_min)
            else
                elapsed_str="N/A"
                remain_str="N/A"
            fi
            printf "  %-10s %-15s %-10s %-12s %-12s\n" "$jid" "${jname:0:15}" "${jnode:0:10}" "$elapsed_str" "$remain_str"
        done
    fi

    if [ ${#pending_lines[@]} -gt 0 ]; then
        [ ${#running_lines[@]} -gt 0 ] && echo ""
        echo -e "${YELLOW}${BOLD}PENDING${NC}"
        printf "  %-10s %-15s %-15s\n" "ID" "Name" "Requested Time"
        echo -e "  ${DIM}──────────────────────────────────────────${NC}"
        for entry in "${pending_lines[@]}"; do
            IFS='|' read -r jid jname jwall <<< "$entry"
            printf "  %-10s %-15s %-15s\n" "$jid" "${jname:0:15}" "$jwall"
        done
    fi
    echo ""
}

cancel_job() {
    echo ""
    local output
    output=$(ssh hpc "oarstat -u ${HPC_USER} 2>/dev/null")
    if ! echo "$output" | grep -q "^[0-9]"; then
        echo -e "${DIM}No running jobs to cancel.${NC}"
        return
    fi
    echo -e "${BOLD}Your jobs:${NC}"
    echo ""
    echo "$output"
    echo ""
    echo -e "Enter a job ID, ${BOLD}all${NC} to cancel everything, or ${CYAN}0${NC} to go back."
    read -p "> " jobid
    [ "$jobid" = "0" ] && return
    if [ "$jobid" = "all" ]; then
        ssh hpc "for jid in \$(oarstat -u ${HPC_USER} 2>/dev/null | awk '/^[0-9]/{print \$1}'); do oardel \$jid; echo \"Cancelled \$jid\"; done"
        echo -e "${GREEN}Done.${NC}"
    elif is_int "$jobid"; then
        ssh hpc "oardel '$jobid'"
        echo -e "${GREEN}Job $jobid cancelled.${NC}"
    elif [ -n "$jobid" ]; then
        echo -e "${RED}Invalid job ID (must be a number).${NC}"
    fi
}

connect_existing() {
    echo ""
    local output
    output=$(ssh hpc "oarstat -u ${HPC_USER} 2>/dev/null")
    if ! echo "$output" | grep -q "^[0-9]"; then
        echo -e "${DIM}No running jobs to connect to.${NC}"
        return
    fi

    local job_ids=($(echo "$output" | awk '/^[0-9]/{print $1}'))
    local jobid=""

    if [ ${#job_ids[@]} -eq 1 ]; then
        jobid="${job_ids[0]}"
        echo -e "Auto-selecting your only running job: ${BOLD}$jobid${NC}"
    else
        echo -e "${BOLD}Your jobs:${NC}"
        echo ""
        echo "$output"
        echo ""
        echo -e "Which job? (or ${CYAN}0${NC} to go back)"
        read -p "> " jobid
        [ "$jobid" = "0" ] && return
    fi

    if [ -z "$jobid" ]; then
        return
    fi
    if ! is_int "$jobid"; then
        echo -e "${RED}Invalid job ID (must be a number).${NC}"
        return
    fi

    echo ""
    echo -e "${BOLD}How do you want to connect?${NC}"
    echo -e "  ${GREEN}1${NC})  Jupyter Lab (opens in browser + shows SSH command)"
    echo -e "  ${GREEN}2${NC})  Terminal only"
    echo -e "  ${CYAN}0${NC})  Back"
    echo ""
    read -p "> " mode
    [ "$mode" = "0" ] && return
    mode="${mode:-1}"
    if ! [[ "$mode" =~ ^[1-2]$ ]]; then
        echo -e "${RED}Choose 1 or 2.${NC}"
        return
    fi

    if [ "$mode" = "2" ]; then
        local node
        node=$(ssh hpc "oarstat -f -j '$jobid' 2>/dev/null | grep 'assigned_hostnames' | awk '{print \$3}'")
        if [ -z "$node" ] || ! is_name "$node"; then
            echo -e "${RED}Could not find node for job $jobid${NC}"
            return
        fi
        echo -e "${CYAN}Connecting to $node...${NC}"
        ssh -t hpc "OAR_JOB_ID='$jobid' oarsh '$node'"
    else
        connect_to_job "$jobid" 8888
    fi
}

welcome
while true; do
    show_menu
    read -p "> " choice
    case $choice in
        1) launch_session ;;
        2) connect_existing ;;
        3) my_jobs ;;
        4) cancel_job ;;
        5) ssh hpc ;;
        0) echo -e "\n${DIM}Bye!${NC}\n"; exit 0 ;;
        *) echo -e "${RED}Invalid choice.${NC}" ;;
    esac
done
HPC_SCRIPT

    # Replace placeholders (use | delimiter to avoid issues with special chars)
    ESCAPED_EMAIL=$(printf '%s\n' "$EMAIL" | sed 's/[&/\]/\\&/g')
    sed -i "s|__USERNAME__|${USERNAME}|g" "${INSTALL_DIR}/hpc-notebook"
    sed -i "s|__EMAIL__|${ESCAPED_EMAIL}|g" "${INSTALL_DIR}/hpc-notebook"
    chmod +x "${INSTALL_DIR}/hpc-notebook"
    echo -e "${GREEN}Installed:${NC} ~/hpc-notebook (alias: hpc)"
fi

if $SETUP_CONV; then
    # Generate Convergence manager
    cat > "${INSTALL_DIR}/conv-manager" << 'CONV_SCRIPT'
#!/bin/bash
# Convergence GPU Cluster Manager for LIP6
# __USERNAME__ - __EMAIL__

BLUE='\033[1;34m'
GREEN='\033[1;32m'
YELLOW='\033[1;33m'
RED='\033[1;31m'
CYAN='\033[1;36m'
DIM='\033[2m'
BOLD='\033[1m'
NC='\033[0m'

CONV_USER="__USERNAME__"
CONV_PORT=9888

is_int()  { [[ "$1" =~ ^[0-9]+$ ]]; }
is_name() { [[ "$1" =~ ^[a-zA-Z0-9_.-]+$ ]]; }
is_path() { [[ "$1" =~ ^[a-zA-Z0-9_.~/-]+$ ]]; }

status_line() { printf "\r\033[K%s" "$1"; }
status_done() { printf "\r\033[K%s\n" "$1"; }
spin_chars=('⠋' '⠙' '⠹' '⠸' '⠼' '⠴' '⠦' '⠧' '⠇' '⠏')

# parse_duration INPUT
# Accepts: 30m, 8h, 3d, 3d 12h, 1d 6h 30m, HH:MM:SS, bare number (hours)
# Outputs SLURM-compatible time (HH:MM:SS or D-HH:MM:SS) to stdout.
parse_duration() {
    local input="${*,,}"  # lowercase
    input=$(echo "$input" | xargs)  # trim
    [ -z "$input" ] && return 1

    # Legacy H:M:S / HH:MM:SS format
    if [[ "$input" =~ ^[0-9]+:[0-9]+:[0-9]+$ ]]; then
        local h m s
        IFS=':' read -r h m s <<< "$input"
        if [ "$h" -ge 24 ]; then
            local d=$(( h / 24 ))
            local rem_h=$(( h % 24 ))
            printf "%d-%02d:%02d:%02d\n" "$d" "$rem_h" "$m" "$s"
        else
            printf "%02d:%02d:%02d\n" "$h" "$m" "$s"
        fi
        return 0
    fi

    local total_minutes=0
    local matched=false

    if [[ "$input" =~ [dhm] ]]; then
        if [[ "$input" =~ ([0-9]+)d ]]; then
            total_minutes=$(( total_minutes + ${BASH_REMATCH[1]} * 1440 ))
            matched=true
        fi
        if [[ "$input" =~ ([0-9]+)h ]]; then
            total_minutes=$(( total_minutes + ${BASH_REMATCH[1]} * 60 ))
            matched=true
        fi
        if [[ "$input" =~ ([0-9]+)m ]]; then
            total_minutes=$(( total_minutes + ${BASH_REMATCH[1]} ))
            matched=true
        fi
        if ! $matched; then return 1; fi
    elif [[ "$input" =~ ^[0-9]+$ ]]; then
        # Bare number = hours
        total_minutes=$(( input * 60 ))
    else
        return 1
    fi

    local total_h=$(( total_minutes / 60 ))
    local total_m=$(( total_minutes % 60 ))
    if [ "$total_h" -ge 24 ]; then
        local d=$(( total_h / 24 ))
        local rem_h=$(( total_h % 24 ))
        printf "%d-%02d:%02d:00\n" "$d" "$rem_h" "$total_m"
    else
        printf "%02d:%02d:00\n" "$total_h" "$total_m"
    fi
    return 0
}

# Total minutes from raw duration input (for limit checks)
duration_to_minutes() {
    local input="${*,,}"
    input=$(echo "$input" | xargs)
    [ -z "$input" ] && echo "0" && return

    if [[ "$input" =~ ^[0-9]+:[0-9]+:[0-9]+$ ]]; then
        local h m s
        IFS=':' read -r h m s <<< "$input"
        echo $(( h * 60 + m ))
        return
    fi

    local total_minutes=0
    if [[ "$input" =~ ([0-9]+)d ]]; then
        total_minutes=$(( total_minutes + ${BASH_REMATCH[1]} * 1440 ))
    fi
    if [[ "$input" =~ ([0-9]+)h ]]; then
        total_minutes=$(( total_minutes + ${BASH_REMATCH[1]} * 60 ))
    fi
    if [[ "$input" =~ ([0-9]+)m ]]; then
        total_minutes=$(( total_minutes + ${BASH_REMATCH[1]} ))
    fi
    if [[ "$input" =~ ^[0-9]+$ ]]; then
        total_minutes=$(( input * 60 ))
    fi
    echo "$total_minutes"
}

welcome() {
    echo ""
    echo -e "${BLUE}================================================${NC}"
    echo -e "${BOLD}     LIP6 Convergence GPU Cluster Manager${NC}"
    echo -e "${DIM}    __USERNAME__ - __EMAIL__${NC}"
    echo -e "${BLUE}================================================${NC}"
    echo ""
    echo -e "${DIM}  10 nodes | 40 x A100 80GB GPUs | SLURM${NC}"
}

show_menu() {
    echo ""
    echo -e "${BOLD}What do you want to do?${NC}"
    echo ""
    echo -e "  ${GREEN}1${NC})  Launch a new GPU session"
    echo -e "  ${GREEN}2${NC})  Reconnect to a running session"
    echo -e "  ${GREEN}3${NC})  View my jobs"
    echo -e "  ${GREEN}4${NC})  Cancel jobs"
    echo -e "  ${GREEN}5${NC})  Cluster status (GPUs, nodes)"
    echo -e "  ${GREEN}6${NC})  SSH into login node"
    echo -e "  ${CYAN}0${NC})  Exit"
    echo ""
}

pick_gpu() {
    echo ""
    echo -e "${BOLD}Which GPU type?${NC}"
    echo ""
    echo -e "  ${GREEN}1${NC})  A100 80GB full     ${DIM}(node01-06, best for large models)${NC}"
    echo -e "  ${GREEN}2${NC})  A100 40GB MIG       ${DIM}(node07-10, good for smaller jobs)${NC}"
    echo -e "  ${CYAN}0${NC})  Back"
    echo ""
    read -p "> " gpu_choice
    case $gpu_choice in
        0) return 1 ;;
        1) GPU_TYPE="a100_7g.80gb" ;;
        2) GPU_TYPE="a100_3g.40gb" ;;
        *) GPU_TYPE="a100_7g.80gb" ;;
    esac
    return 0
}

launch_session() {
    pick_gpu || return

    echo ""
    echo -e "${BOLD}How many GPUs?${NC}"
    echo -e "  ${DIM}Press Enter for 1 (max 4 per node for full, 8 for MIG), 0 to go back${NC}"
    read -p "> " num_gpus
    [ "$num_gpus" = "0" ] && return
    num_gpus="${num_gpus:-1}"
    if ! is_int "$num_gpus"; then
        echo -e "${RED}GPU count must be a number (e.g. 1, 2, 4).${NC}"
        return
    fi

    echo ""
    echo -e "${BOLD}How long do you need?${NC}"
    echo -e "  ${DIM}e.g. 8h, 3d, 1d 6h 30m, 08:00:00 — Enter for 8h, 0 to go back${NC}"
    read -p "> " wall_input
    [ "$wall_input" = "0" ] && return
    wall_input="${wall_input:-8h}"
    wall=$(parse_duration "$wall_input")
    if [ $? -ne 0 ] || [ -z "$wall" ]; then
        echo -e "${RED}Invalid duration. Examples: 8h, 3d, 1d 6h 30m, 08:00:00${NC}"
        return
    fi

    # Warn if > 15 days
    local total_min=$(duration_to_minutes "$wall_input")
    if [ "$total_min" -gt 21600 ] 2>/dev/null; then
        echo -e "${YELLOW}Warning: Duration exceeds the 15-day maximum for Convergence.${NC}"
    fi

    echo ""
    echo -e "${BOLD}Job name?${NC}"
    echo -e "  ${DIM}Press Enter for 'gpu-session', 0 to go back${NC}"
    read -p "> " job_name
    [ "$job_name" = "0" ] && return
    job_name="${job_name:-gpu-session}"
    if ! is_name "$job_name"; then
        echo -e "${RED}Invalid job name. Use only letters, digits, hyphens, underscores.${NC}"
        return
    fi

    echo ""
    echo -e "${BOLD}How do you want to work?${NC}"
    echo ""
    echo -e "  ${GREEN}1${NC})  Jupyter Lab + Terminal  ${DIM}(recommended)${NC}"
    echo -e "      ${DIM}Persistent — survives disconnect. Opens browser + shows SSH command.${NC}"
    echo -e "  ${GREEN}2${NC})  Terminal only  ${DIM}(interactive)${NC}"
    echo -e "      ${DIM}Direct shell on compute node. Ends when you disconnect.${NC}"
    echo -e "  ${GREEN}3${NC})  Submit a custom script"
    echo -e "      ${DIM}Run your own batch script with SLURM.${NC}"
    echo -e "  ${CYAN}0${NC})  Back"
    echo ""
    read -p "> " mode
    [ "$mode" = "0" ] && return
    mode="${mode:-1}"
    if ! [[ "$mode" =~ ^[1-3]$ ]]; then
        echo -e "${RED}Choose 1, 2, or 3.${NC}"
        return
    fi

    if [ "$mode" = "3" ]; then
        submit_custom "$num_gpus" "$wall" "$job_name"
        return
    fi

    if [ "$mode" = "2" ]; then
        echo ""
        echo -e "${CYAN}Requesting interactive session: ${num_gpus}x ${GPU_TYPE}, ${wall}...${NC}"
        echo -e "${DIM}This is interactive — ends when you disconnect.${NC}"
        echo ""
        ssh -t conv "salloc --job-name='${job_name}' --nodes=1 --gpus-per-node='${GPU_TYPE}:${num_gpus}' --time='${wall}'"
        return
    fi

    echo ""
    echo -e "${CYAN}Submitting Jupyter Lab: ${num_gpus}x ${GPU_TYPE}, ${wall}...${NC}"

    # Check if Jupyter is available
    status_line "  ● Checking Jupyter installation..."
    jupyter_check=$(ssh conv 'source /etc/profile.d/modules.sh 2>/dev/null; module purge; module load python/anaconda3; eval "$(conda shell.bash hook)"; which jupyter 2>/dev/null' 2>/dev/null)
    if [ -z "$jupyter_check" ]; then
        status_done "  $(echo -e "${YELLOW}! Jupyter not found. Installing...${NC}")"
        ssh conv 'source /etc/profile.d/modules.sh 2>/dev/null; module purge; module load python/anaconda3; eval "$(conda shell.bash hook)"; pip install --quiet jupyterlab' 2>/dev/null
        if [ $? -eq 0 ]; then
            echo -e "  ${GREEN}✓ Jupyter Lab installed${NC}"
        else
            echo -e "  ${RED}✗ Failed to install Jupyter. Check manually.${NC}"
            return
        fi
    else
        status_done "  $(echo -e "${GREEN}✓${NC} Jupyter available")"
    fi

    JOBID=$(ssh conv bash -s "$num_gpus" "$GPU_TYPE" "$wall" "$CONV_PORT" "$job_name" << 'REMOTE'
NUM_GPUS="$1"
GPU_TYPE="$2"
WALL="$3"
PORT="$4"
JOB_NAME="$5"
cat > ~/._conv_jupyter.sh << JOBSCRIPT
#!/bin/bash
#SBATCH --job-name=${JOB_NAME}
#SBATCH --nodes=1
#SBATCH --gpus-per-node=${GPU_TYPE}:${NUM_GPUS}
#SBATCH --time=${WALL}
#SBATCH --mail-type=ALL
#SBATCH --mail-user=__EMAIL__
#SBATCH --output=%x-%j.out
#SBATCH --error=%x-%j.err

source /etc/profile.d/modules.sh
module purge
module load python/anaconda3
eval "\$(conda shell.bash hook)"

jupyter lab --ip=0.0.0.0 --no-browser --port=${PORT}
JOBSCRIPT
sbatch ~/._conv_jupyter.sh 2>&1 | grep -oP 'Submitted batch job \K[0-9]+'
REMOTE
    )

    if [ -z "$JOBID" ] || ! is_int "$JOBID"; then
        echo -e "${RED}Failed to submit job.${NC}"
        return
    fi

    echo -e "${GREEN}Job $JOBID submitted.${NC} Waiting for it to start..."
    echo -e "${DIM}(Convergence queue can take minutes to hours depending on load)${NC}"
    sleep 5

    # Trap Ctrl+C during wait
    local wait_interrupted=false
    trap 'wait_interrupted=true' INT

    local attempts=0
    local spin_idx=0
    while true; do
        if $wait_interrupted; then
            status_done ""
            echo ""
            echo -e "${YELLOW}Job $JOBID is still queued. You'll get an email when it starts.${NC}"
            echo -e "Use option 2 to reconnect later."
            trap - INT
            return
        fi
        STATE=$(ssh conv "squeue -j '$JOBID' -h -o '%T' 2>/dev/null" 2>/dev/null)
        if [ "$STATE" = "RUNNING" ]; then
            status_done "  $(echo -e "${GREEN}✓ Job $JOBID is running${NC}")"
            break
        elif [ "$STATE" = "FAILED" ] || [ "$STATE" = "CANCELLED" ] || [ "$STATE" = "TIMEOUT" ]; then
            status_done ""
            echo -e "${RED}Job failed (state: $STATE)${NC}"
            echo -e "Check logs: ${DIM}ssh conv 'cat ~/${job_name}-${JOBID}.err'${NC}"
            trap - INT
            return
        elif [ -z "$STATE" ]; then
            local sacct_state
            sacct_state=$(ssh conv "sacct -j '$JOBID' --format=State -X --noheader 2>/dev/null | tr -d ' '" 2>/dev/null)
            if [ -n "$sacct_state" ] && [ "$sacct_state" != "PENDING" ] && [ "$sacct_state" != "RUNNING" ]; then
                status_done ""
                echo -e "${RED}Job ended (state: ${sacct_state:-unknown})${NC}"
                echo -e "Check logs: ${DIM}ssh conv 'cat ~/${job_name}-${JOBID}.err'${NC}"
                trap - INT
                return
            fi
        fi
        attempts=$((attempts + 1))
        if [ $attempts -gt 120 ]; then
            status_done ""
            echo ""
            echo -e "${YELLOW}Job $JOBID is still queued after 10 min. You'll get an email when it starts.${NC}"
            echo -e "Use option 2 to reconnect later."
            trap - INT
            return
        fi
        local sc="${spin_chars[$((spin_idx % ${#spin_chars[@]}))]}"
        spin_idx=$((spin_idx + 1))
        status_line "  ${sc} ${STATE:-PENDING} — waiting for GPUs ($((attempts * 5))s) — Ctrl+C to stop waiting"
        sleep 5
    done

    trap - INT
    connect_to_job "$JOBID" "$mode" "$job_name"
}

submit_custom() {
    local num_gpus="$1"
    local wall="$2"
    local job_name="$3"

    echo ""
    echo -e "${BOLD}Path to your script on the cluster?${NC}"
    echo -e "  ${DIM}e.g. ~/train.sh — 0 to go back${NC}"
    read -p "> " script_path
    [ "$script_path" = "0" ] && return

    if [ -z "$script_path" ]; then
        echo -e "${RED}No script provided.${NC}"
        return
    fi
    if ! is_path "$script_path"; then
        echo -e "${RED}Invalid path. Allowed characters: letters, digits, ., _, ~, /, -${NC}"
        return
    fi

    echo ""
    echo -e "${CYAN}Submitting ${script_path}: ${num_gpus}x ${GPU_TYPE}, ${wall}...${NC}"

    JOBID=$(ssh conv "sbatch --job-name='${job_name}' --nodes=1 --gpus-per-node='${GPU_TYPE}:${num_gpus}' --time='${wall}' --mail-type=ALL --mail-user=__EMAIL__ --output=%x-%j.out --error=%x-%j.err '${script_path}' 2>&1 | grep -oP 'Submitted batch job \K[0-9]+'")

    if [ -z "$JOBID" ] || ! is_int "$JOBID"; then
        echo -e "${RED}Failed to submit job.${NC}"
        return
    fi

    echo -e "${GREEN}Job $JOBID submitted!${NC}"
    echo -e "  Check status:  ${DIM}option 3${NC}"
    echo -e "  Check logs:    ${DIM}ssh conv 'cat ~/${job_name}-${JOBID}.out'${NC}"
    echo -e "  Cancel:        ${DIM}option 4${NC}"
}

connect_to_job() {
    local jobid="$1"
    local mode="${2:-1}"
    local job_name="${3:-gpu-session}"

    local node
    node=$(ssh conv "squeue -j '$jobid' -h -o '%N' 2>/dev/null" 2>/dev/null)
    if [ -z "$node" ] || ! is_name "$node"; then
        echo -e "${RED}Could not find node for job $jobid${NC}"
        return
    fi

    echo -e "${CYAN}Running on ${BOLD}$node${NC}${CYAN}. Waiting for Jupyter...${NC}"

    local url=""
    local spin_idx=0
    for i in $(seq 1 30); do
        url=$(ssh conv "grep -o 'http://[^ ]*' ~/*-'${jobid}'.err 2>/dev/null | tail -1" 2>/dev/null)
        if [ -n "$url" ]; then
            status_done "  $(echo -e "${GREEN}✓${NC} Jupyter is ready")"
            break
        fi
        local sc="${spin_chars[$((spin_idx % ${#spin_chars[@]}))]}"
        spin_idx=$((spin_idx + 1))
        status_line "  ${sc} Waiting for Jupyter to start... ($((i * 2))s)"
        sleep 2
    done

    if [ -z "$url" ]; then
        status_done ""
        echo -e "${RED}Jupyter didn't start.${NC}"
        echo -e "Check logs: ${DIM}ssh conv 'cat ~/*-${jobid}.err'${NC}"
        return
    fi

    local remote_port=$(echo "$url" | grep -oP ':\K[0-9]+(?=/)' | head -1)
    remote_port="${remote_port:-$CONV_PORT}"
    local local_port="$remote_port"
    local local_url=$(echo "$url" | sed "s|http://[^:]*:${remote_port}|http://localhost:${local_port}|")

    echo ""
    echo -e "${GREEN}================================================${NC}"
    echo -e "${GREEN}  GPU Session ready!${NC}"
    echo -e "${GREEN}================================================${NC}"
    echo ""
    echo -e "  ${BOLD}Job:${NC}    $jobid"
    echo -e "  ${BOLD}Node:${NC}   $node"
    echo -e "  ${BOLD}Port:${NC}   $remote_port"
    echo -e "  ${BOLD}URL:${NC}    ${CYAN}$local_url${NC}"
    echo ""
    echo -e "${CYAN}Opening Jupyter in browser...${NC}"
    if command -v xdg-open &>/dev/null; then
        xdg-open "$local_url" 2>/dev/null &
    elif command -v open &>/dev/null; then
        open "$local_url" &
    fi
    echo ""
    echo -e "${BOLD}To open a terminal on $node, run in another tab:${NC}"
    echo ""
    echo -e "  ${GREEN}ssh -t -J conv ${node}.convergence.lip6.fr${NC}"
    echo ""
    echo -e "${DIM}Tunnel active (port ${remote_port}). Ctrl+C to disconnect (job keeps running).${NC}"
    echo ""
    ssh -N -J conv -L "${local_port}:localhost:${remote_port}" "${node}.convergence.lip6.fr"
}

my_jobs() {
    echo ""
    status_line "  ● Fetching jobs..."
    if ! ssh conv "squeue -h -u '${CONV_USER}' 2>/dev/null" 2>/dev/null | grep -q .; then
        status_done "  $(echo -e "${DIM}No jobs found.${NC}")"
        echo ""
        return
    fi

    status_done ""

    # Fetch running and pending separately with rich formatting
    local running
    running=$(ssh conv "squeue -h -u '${CONV_USER}' -t RUNNING -o '  %-8i %-20j %-12M %-12l %-12L %-15R' 2>/dev/null" 2>/dev/null)
    local pending
    pending=$(ssh conv "squeue -h -u '${CONV_USER}' -t PENDING -o '  %-8i %-20j %-12l %-20R' 2>/dev/null" 2>/dev/null)

    if [ -n "$running" ]; then
        echo -e "${GREEN}${BOLD}RUNNING${NC}"
        printf "  %-8s %-20s %-12s %-12s %-12s %-15s\n" "JobID" "Name" "Elapsed" "TimeLimit" "TimeLeft" "Node"
        echo -e "  ${DIM}────────────────────────────────────────────────────────────────────────────────${NC}"
        echo "$running"
    fi

    if [ -n "$pending" ]; then
        [ -n "$running" ] && echo ""
        echo -e "${YELLOW}${BOLD}PENDING${NC}"
        printf "  %-8s %-20s %-12s %-20s\n" "JobID" "Name" "TimeLimit" "Reason"
        echo -e "  ${DIM}──────────────────────────────────────────────────────────────${NC}"
        echo "$pending"
    fi
    echo ""
}

cancel_job() {
    echo ""
    local output
    output=$(ssh conv "squeue -u '${CONV_USER}' 2>/dev/null" 2>/dev/null)
    if ! ssh conv "squeue -h -u '${CONV_USER}' 2>/dev/null" 2>/dev/null | grep -q .; then
        echo -e "${DIM}No running jobs to cancel.${NC}"
        return
    fi
    echo -e "${BOLD}Your jobs:${NC}"
    echo ""
    echo "$output"
    echo ""
    echo -e "Enter a job ID, ${BOLD}all${NC} to cancel everything, or ${CYAN}0${NC} to go back."
    read -p "> " jobid
    [ "$jobid" = "0" ] && return
    if [ "$jobid" = "all" ]; then
        ssh conv "scancel -u '${CONV_USER}' 2>/dev/null" 2>/dev/null
        echo -e "${GREEN}All jobs cancelled.${NC}"
    elif is_int "$jobid"; then
        ssh conv "scancel '$jobid' 2>/dev/null" 2>/dev/null
        echo -e "${GREEN}Job $jobid cancelled.${NC}"
    elif [ -n "$jobid" ]; then
        echo -e "${RED}Invalid job ID (must be a number, or 'all').${NC}"
    fi
}

cluster_status() {
    echo ""
    echo -e "${BOLD}Cluster status:${NC}"
    echo ""
    ssh conv "sinfo -p convergence --Node -O 'nodelist:10,cpusstate:16,memory:10,allocmem:10,gres:35,gresused:35,statelong:12' 2>/dev/null" 2>/dev/null
    echo ""
}

connect_existing() {
    echo ""
    local output
    output=$(ssh conv "squeue -u '${CONV_USER}' 2>/dev/null" 2>/dev/null)
    if ! ssh conv "squeue -h -u '${CONV_USER}' 2>/dev/null" 2>/dev/null | grep -q .; then
        echo -e "${DIM}No running jobs to connect to.${NC}"
        return
    fi

    local job_ids=($(ssh conv "squeue -h -u '${CONV_USER}' -o '%i' 2>/dev/null" 2>/dev/null))
    local jobid=""
    local job_name=""

    if [ ${#job_ids[@]} -eq 1 ]; then
        jobid="${job_ids[0]}"
        job_name=$(ssh conv "squeue -h -j '${jobid}' -o '%j' 2>/dev/null" 2>/dev/null)
        echo -e "Auto-selecting your only running job: ${BOLD}$jobid${NC}"
    else
        echo -e "${BOLD}Your jobs:${NC}"
        echo ""
        echo "$output"
        echo ""
        echo -e "Which job? (or ${CYAN}0${NC} to go back)"
        read -p "> " jobid
        [ "$jobid" = "0" ] && return
        if [ -n "$jobid" ]; then
            job_name=$(ssh conv "squeue -j '$jobid' -h -o '%j' 2>/dev/null" 2>/dev/null)
        fi
    fi

    if [ -z "$jobid" ]; then
        return
    fi
    if ! is_int "$jobid"; then
        echo -e "${RED}Invalid job ID (must be a number).${NC}"
        return
    fi

    echo ""
    echo -e "${BOLD}How do you want to connect?${NC}"
    echo -e "  ${GREEN}1${NC})  Jupyter Lab (opens in browser + shows SSH command)"
    echo -e "  ${GREEN}2${NC})  Terminal only"
    echo -e "  ${CYAN}0${NC})  Back"
    echo ""
    read -p "> " mode
    [ "$mode" = "0" ] && return
    mode="${mode:-1}"
    if ! [[ "$mode" =~ ^[1-2]$ ]]; then
        echo -e "${RED}Choose 1 or 2.${NC}"
        return
    fi

    if [ "$mode" = "2" ]; then
        local node
        node=$(ssh conv "squeue -j '$jobid' -h -o '%N' 2>/dev/null" 2>/dev/null)
        if [ -z "$node" ] || ! is_name "$node"; then
            echo -e "${RED}Could not find node for job $jobid${NC}"
            return
        fi
        echo -e "${CYAN}Connecting to $node...${NC}"
        ssh -t -J conv "${node}.convergence.lip6.fr"
    else
        connect_to_job "$jobid" "$mode" "${job_name:-gpu-session}"
    fi
}

welcome
while true; do
    show_menu
    read -p "> " choice
    case $choice in
        1) launch_session ;;
        2) connect_existing ;;
        3) my_jobs ;;
        4) cancel_job ;;
        5) cluster_status ;;
        6) ssh conv ;;
        0) echo -e "\n${DIM}Bye!${NC}\n"; exit 0 ;;
        *) echo -e "${RED}Invalid choice.${NC}" ;;
    esac
done
CONV_SCRIPT

    # Replace placeholders (use | delimiter to avoid issues with special chars)
    ESCAPED_EMAIL=$(printf '%s\n' "$EMAIL" | sed 's/[&/\]/\\&/g')
    sed -i "s|__USERNAME__|${USERNAME}|g" "${INSTALL_DIR}/conv-manager"
    sed -i "s|__EMAIL__|${ESCAPED_EMAIL}|g" "${INSTALL_DIR}/conv-manager"
    chmod +x "${INSTALL_DIR}/conv-manager"
    echo -e "${GREEN}Installed:${NC} ~/conv-manager (alias: conv)"
fi

# ---- Shell aliases ----

echo ""
echo -e "${BOLD}Step 7: Setting up shell aliases${NC}"
echo ""

setup_alias() {
    local file="$1"
    local name="$2"
    local cmd="$3"

    if [ -f "$file" ]; then
        # Remove old alias if exists (use mktemp for safe temp files)
        local tmpfile
        tmpfile=$(mktemp "${file}.XXXXXX")
        grep -v "alias ${name}=" "$file" > "$tmpfile" 2>/dev/null || true
        mv "$tmpfile" "$file"
    fi
    echo "alias ${name}=\"${cmd}\"" >> "$file"
}

# Detect shell
SHELL_NAME=$(basename "$SHELL" 2>/dev/null || echo "bash")

if [ "$SHELL_NAME" = "fish" ]; then
    SHELL_CONFIG="$HOME/.config/fish/config.fish"
    mkdir -p "$(dirname "$SHELL_CONFIG")"
    if $SETUP_HPC; then
        tmpfile=$(mktemp "${SHELL_CONFIG}.XXXXXX")
        grep -v 'alias hpc=' "$SHELL_CONFIG" > "$tmpfile" 2>/dev/null || true
        mv "$tmpfile" "$SHELL_CONFIG" 2>/dev/null || true
        echo 'alias hpc="~/hpc-notebook"' >> "$SHELL_CONFIG"
    fi
    if $SETUP_CONV; then
        tmpfile=$(mktemp "${SHELL_CONFIG}.XXXXXX")
        grep -v 'alias conv=' "$SHELL_CONFIG" > "$tmpfile" 2>/dev/null || true
        mv "$tmpfile" "$SHELL_CONFIG" 2>/dev/null || true
        echo 'alias conv="~/conv-manager"' >> "$SHELL_CONFIG"
    fi
elif [ "$SHELL_NAME" = "zsh" ]; then
    SHELL_CONFIG="$HOME/.zshrc"
    $SETUP_HPC && setup_alias "$SHELL_CONFIG" "hpc" "~/hpc-notebook"
    $SETUP_CONV && setup_alias "$SHELL_CONFIG" "conv" "~/conv-manager"
else
    SHELL_CONFIG="$HOME/.bashrc"
    $SETUP_HPC && setup_alias "$SHELL_CONFIG" "hpc" "~/hpc-notebook"
    $SETUP_CONV && setup_alias "$SHELL_CONFIG" "conv" "~/conv-manager"
fi

echo -e "${GREEN}Aliases added to ${SHELL_CONFIG}${NC}"

# ---- Remote bashrc setup ----

echo ""
echo -e "${BOLD}Step 8: Setting up remote cluster aliases${NC}"
echo ""

if $SETUP_HPC; then
    echo -e "${CYAN}Configuring HPC (.bashrc)...${NC}"
    ssh hpc bash -s "$USERNAME" "$EMAIL" "$HPC_STORAGE" << 'REMOTE_HPC'
USERNAME="$1"
EMAIL="$2"
HPC_STORAGE="$3"

# Backup before modifying
if [ -f ~/.bashrc ]; then
    cp ~/.bashrc ~/.bashrc.pre-lip6-setup
fi

# Only add if not already present
if ! grep -q "HPC Aliases" ~/.bashrc 2>/dev/null; then
    cat >> ~/.bashrc << ALIASES

# === HPC Aliases ===

hpc-conda() {
    source /etc/profile.d/modules.sh
    module purge
    module load python/anaconda3
    eval "\\\$(conda shell.bash hook)"
}

hpc-small()  { oarsub -l /nodes=1/core=4,walltime=\${1:-8:0:0} -p "host like 'big%'" -I; }
hpc-medium() { oarsub -l /nodes=1/core=12,walltime=\${1:-8:0:0} -p "host like 'big%'" -I; }
hpc-large()  { oarsub -l /nodes=1/core=24,walltime=\${1:-8:0:0} -p "host like 'big%'" -I; }
hpc-bigram() { oarsub -l /nodes=1/core=20,walltime=\${1:-8:0:0} -p "host='big25'" -I; }
hpc-grab()   { oarsub -l /nodes=1/core=\${1:-4},walltime=\${2:-8:0:0} -p "host like 'big%'" -I; }

alias hpc-jobs='oarstat'
alias hpc-myjobs='oarstat -u ${USERNAME}'
alias hpc-kill='oardel'
alias hpc-connect='oarsub -C'
alias hpc-nodes='oarnodes -l'
alias hpc-run='oarsub -S'

hpc-log() { cat ~/OAR."\$1".stdout; }
hpc-err() { cat ~/OAR."\$1".stderr; }

hpc-help() {
    echo "=== HPC Quick Reference ==="
    echo ""
    echo "SESSIONS (all default 8h, override: hpc-small 24:0:0)"
    echo "  hpc-small  [time]    4 cores  (~16-24 GB RAM)"
    echo "  hpc-medium [time]   12 cores  (~48-72 GB RAM)"
    echo "  hpc-large  [time]   24 cores  (~96 GB RAM)"
    echo "  hpc-bigram [time]   20 cores on big25 (128 GB RAM)"
    echo "  hpc-grab CORES TIME  custom, e.g. hpc-grab 48 24:0:0"
    echo ""
    echo "JOBS"
    echo "  hpc-jobs             list all running jobs"
    echo "  hpc-myjobs           list my jobs"
    echo "  hpc-run ~/script.sh  submit batch job (up to 1000h)"
    echo "  hpc-connect JOBID    ssh into a running job"
    echo "  hpc-kill JOBID       kill a job"
    echo "  hpc-log JOBID        view job stdout"
    echo "  hpc-err JOBID        view job stderr"
    echo ""
    echo "SETUP"
    echo "  hpc-conda            load conda + anaconda3 module"
    echo "  hpc-nodes            list all cluster nodes"
    echo ""
    echo "STORAGE"
    echo "  ~/                   home dir (NFS shared across nodes)"
    echo "  ${HPC_STORAGE}   team storage"
}
ALIASES
    echo "HPC aliases added."
else
    echo "HPC aliases already present."
fi
REMOTE_HPC
    echo -e "${GREEN}HPC aliases configured.${NC}"
fi

if $SETUP_CONV; then
    echo -e "${CYAN}Configuring Convergence (.bashrc)...${NC}"
    ssh conv bash -s "$USERNAME" "$EMAIL" << 'REMOTE_CONV'
USERNAME="$1"
EMAIL="$2"

# Backup before modifying
if [ -f ~/.bashrc ]; then
    cp ~/.bashrc ~/.bashrc.pre-lip6-setup
fi

if ! grep -q "Convergence Cluster Aliases" ~/.bashrc 2>/dev/null; then
    cat >> ~/.bashrc << ALIASES

# === Convergence Cluster Aliases ===

conv-conda() {
    source /etc/profile.d/modules.sh 2>/dev/null
    module purge
    module load python/anaconda3
    eval "\\\$(conda shell.bash hook)"
}

alias conv-jobs='squeue -u ${USERNAME}'
alias conv-status='sinfo -p convergence --Node -O "nodelist:10,cpusstate:16,gres:35,gresused:35,statelong:12"'
alias conv-kill='scancel'

conv-log() { cat ~/*-"\$1".out 2>/dev/null; }
conv-err() { cat ~/*-"\$1".err 2>/dev/null; }

conv-help() {
    echo "=== Convergence Quick Reference ==="
    echo ""
    echo "GPU TYPES (must specify in reservations)"
    echo "  a100_7g.80gb    Full A100 80GB (node01-06)"
    echo "  a100_3g.40gb    MIG A100 40GB  (node07-10)"
    echo ""
    echo "INTERACTIVE"
    echo "  salloc --gpus-per-node=a100_7g.80gb:1 --time=08:00:00"
    echo "  salloc --gpus-per-node=a100_3g.40gb:2 --time=08:00:00"
    echo "  salloc --exclusive --mem=0 --time=08:00:00    (full node)"
    echo ""
    echo "BATCH"
    echo "  sbatch my_script.sh"
    echo ""
    echo "JOBS"
    echo "  conv-jobs        list my jobs"
    echo "  conv-status      cluster GPU usage"
    echo "  conv-kill JOBID  cancel a job"
    echo "  conv-log JOBID   view job stdout"
    echo "  conv-err JOBID   view job stderr"
    echo ""
    echo "SETUP"
    echo "  conv-conda       load conda + anaconda3"
    echo ""
    echo "STORAGE"
    echo "  ~/               home (300TB NFS, shared)"
    echo "  /scratch/        local NVME (1.6TB, per-node, NOT shared)"
    echo ""
    echo "LIMITS"
    echo "  Default time:    1 hour"
    echo "  Max time:        15 days"
    echo "  Per GPU default: 8 threads + 64GB RAM"
}
ALIASES
    echo "Convergence aliases added."
else
    echo "Convergence aliases already present."
fi

# Disable conda auto-activate
conda config --set auto_activate_base false 2>/dev/null || true
REMOTE_CONV
    echo -e "${GREEN}Convergence aliases configured.${NC}"
fi

# ---- Done ----

echo ""
echo -e "${GREEN}================================================================${NC}"
echo -e "${GREEN}  Setup complete!${NC}"
echo -e "${GREEN}================================================================${NC}"
echo ""
echo -e "${BOLD}Open a new terminal, then:${NC}"
echo ""
if $SETUP_HPC; then
    echo -e "  ${GREEN}hpc${NC}   — CPU cluster manager (OAR, up to 48 cores)"
fi
if $SETUP_CONV; then
    echo -e "  ${GREEN}conv${NC}  — GPU cluster manager (SLURM, A100 GPUs)"
fi
echo ""
echo -e "${BOLD}Quick SSH:${NC}"
echo ""
if $SETUP_HPC; then
    echo -e "  ${GREEN}ssh hpc${NC}    — login to HPC cluster"
fi
if $SETUP_CONV; then
    echo -e "  ${GREEN}ssh conv${NC}   — login to Convergence"
fi
echo ""
echo -e "${BOLD}On the cluster, type:${NC}"
echo ""
if $SETUP_HPC; then
    echo -e "  ${GREEN}hpc-help${NC}   — HPC commands reference"
fi
if $SETUP_CONV; then
    echo -e "  ${GREEN}conv-help${NC}  — Convergence commands reference"
fi
echo ""
echo -e "${DIM}Happy computing!${NC}"
echo ""
